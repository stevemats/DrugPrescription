{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import ipywidgets\n",
    "from ipywidgets import interact\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 5)\n",
    "plt.style.use('fivethirtyeight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the Dataset\n",
    "data = pd.read_csv('drug.csv')\n",
    "\n",
    "# lets print the shape of the dataset\n",
    "print(\"The Shape of the Dataset :\", data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the head of the dataset\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets Explore Some of the Important Column in the dataset\n",
    "\n",
    "print(\"Number of Unique Drugs present in the Dataset :\", data['drugName'].nunique())\n",
    "print(\"Number of Unique Medical Conditions present in the Dataset :\", data['condition'].nunique())\n",
    "\n",
    "print(\"\\nThe Time Period of Collecting the Data\")\n",
    "print(\"Starting Date :\", data['date'].min())\n",
    "print(\"Ending Date :\", data['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets summarize the Dataset\n",
    "data[['rating','usefulCount']].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the Number and Name of the Drugs with 0 Useful Count in Details\n",
    "print(\"Analysis on Useless Drugs\")\n",
    "print(\"----------------------------\")\n",
    "print(\"The Number of Drugs with No Useful Count :\", data[data['usefulCount'] == 0].count()[0])\n",
    "\n",
    "# Lets Check the Number of Drugs with No Usesful Count with Review Greater than or Equal to 8\n",
    "print(\"Number of Good Drugs with Lesser Useful Count :\", data[(data['usefulCount'] == 0) &\n",
    "                                                data['rating'] >= 8].count()[0])\n",
    "\n",
    "# Lets Check the Average Rating of the Drugs with No Useful Count\n",
    "print(\"Average Rating of Drugs with No Useful Count : {0:.2f}\".format(data[data['usefulCount'] == 0]['rating'].mean()))\n",
    "\n",
    "print(\"\\nAnalysis on Useful Drugs\")\n",
    "print(\"----------------------------\")\n",
    "print(\"The Number of Drugs with Greater than 1000 Useful Counts :\", data[data['usefulCount'] > 1000].count()[0])\n",
    "print(\"Average Rating of Drugs with 1000+ Useful Counts :\", data[data['usefulCount'] > 1000]['rating'].mean())\n",
    "print(\"\\nName and Condition of these Drugs: \\n\\n\", \n",
    "    data[data['usefulCount'] > 1000][['drugName','condition']].reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets summarize Categorical data also\n",
    "data[['drugName','condition','review']].describe(include = 'object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check for Missing Values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we know that condition is an Important Column, so we will delete all the records where Condition is Missing\n",
    "data = data.dropna()\n",
    "\n",
    "# lets check the Missing values now\n",
    "data.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the Distribution of Rating and Useful Count\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 4)\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.distplot(data['rating'])\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.distplot(data['usefulCount'])\n",
    "\n",
    "plt.suptitle('Distribution of Rating and Useful Count \\n ', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the Impact of Ratings on Usefulness\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (15, 4)\n",
    "sns.barplot(data['rating'], data['usefulCount'], palette = 'hot')\n",
    "plt.grid()\n",
    "plt.xlabel('\\n Ratings')\n",
    "plt.ylabel('Count\\n', fontsize = 20)\n",
    "plt.title('\\n Rating vs Usefulness \\n', fontsize = 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking whether Length of Review has any Impact on Ratings of the Drugs\n",
    "\n",
    "# for that we need to create a new column to calculate length of the reviews\n",
    "data['len']  = data['review'].apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the Impact of Length of Reviews on Ratings\n",
    "data[['rating','len']].groupby(['rating']).agg(['min','mean','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the Highest Length Review\n",
    "print(\"Length of Longest Review\", data['len'].max())\n",
    "data['review'][data['len'] == data['len'].max()].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as it is clear that the reviews have so many unnecassry things such as Stopwords, Punctuations, numbers etc\n",
    "\n",
    "# First lets remove Punctuations from the Reviews\n",
    "def punctuation_removal(messy_str):\n",
    "    clean_list = [char for char in messy_str if char not in string.punctuation]\n",
    "    clean_str = ''.join(clean_list)\n",
    "    return clean_str\n",
    "\n",
    "data['review'] = data['review'].apply(punctuation_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets Remove the Stopwords also\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "stop.append(\"i'm\")\n",
    "\n",
    "stop_words = []\n",
    "\n",
    "for item in stop: \n",
    "    new_item = punctuation_removal(item)\n",
    "    stop_words.append(new_item) \n",
    "\n",
    "def stopwords_removal(messy_str):\n",
    "    messy_str = word_tokenize(messy_str)\n",
    "    return [word.lower() for word in messy_str \n",
    "            if word.lower() not in stop_words ]\n",
    "\n",
    "data['review'] = data['review'].apply(stopwords_removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets remove the Numbers also\n",
    "\n",
    "import re\n",
    "def drop_numbers(list_text):\n",
    "    list_text_new = []\n",
    "    for i in list_text:\n",
    "        if not re.search('\\d', i):\n",
    "            list_text_new.append(i)\n",
    "    return ' '.join(list_text_new)\n",
    "\n",
    "data['review'] = data['review'].apply(drop_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for using Sentiment Analyzer we will have to dowload the Vader Lexicon from NLTK\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets calculate the Sentiment from Reviews\n",
    "\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "train_sentiments = []\n",
    "\n",
    "for i in data['review']:\n",
    "    train_sentiments.append(sid.polarity_scores(i).get('compound'))\n",
    "    \n",
    "train_sentiments = np.asarray(train_sentiments)\n",
    "data['sentiment'] = pd.Series(data=train_sentiments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check Impact of Sentiment on Reviews\n",
    "data[['rating','sentiment']].groupby(['rating']).agg(['min','mean','max'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# as we can see that Sentiment and length of the review are not related to Reviews, we will drop the sentiment column\n",
    "\n",
    "# lets remove the unique Id, date, review, len, and sentiment column also\n",
    "data = data.drop(['date','uniqueID','sentiment','review','len'], axis = 1)\n",
    "\n",
    "# lets check the name of columns now\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets Calculate an Effective Rating\n",
    "\n",
    "\n",
    "min_rating = data['rating'].min()\n",
    "max_rating = data['rating'].max()\n",
    "\n",
    "def scale_rating(rating):\n",
    "    rating -= min_rating\n",
    "    rating = rating/(max_rating -1)\n",
    "    rating *= 5\n",
    "    rating = int(round(rating,0))\n",
    "    \n",
    "    if(int(rating) == 0 or int(rating)==1 or int(rating)==2):\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "    \n",
    "data['eff_score'] = data['rating'].apply(scale_rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets also calculate Usefulness Score\n",
    "\n",
    "data['usefulness'] = data['rating']*data['usefulCount']*data['eff_score']\n",
    "\n",
    "# lets check the Top 10 Most Useful Drugs with their Respective Conditions\n",
    "data[['drugName','condition','usefulness']][data['usefulness'] > \n",
    "                            data['usefulness'].mean()].sort_values(by = 'usefulness', \n",
    "                                        ascending = False).head(10).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets calculate the Number of Useless and Useful Drugs for Each Condition\n",
    "\n",
    "@interact\n",
    "def check(condition = list(data['condition'].value_counts().index)):\n",
    "    return data[data['condition'] == condition]['eff_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check this in Graph, \n",
    "\n",
    "popular_conditions = ('Birth Control','Depression','Pain','Anxiety','Acne','Bipolar Disorde','Insomnia','Weight Loss',\n",
    "                      'Obesity','ADHD', 'Diabetes, Type 2', 'Emergency Contraception', 'High Blood Pressure','Migrane')\n",
    "conditions = data.loc[data['condition'].isin(popular_conditions)]\n",
    "\n",
    "sns.barplot(x = conditions['condition'], y = conditions['rating'], hue = data['eff_score'], \n",
    "     palette = 'autumn')\n",
    "plt.title('Conditions vs Effective Number of Drugs')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.ylabel(' ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check the Most Common Conditions\n",
    "\n",
    "print(\"Number of Unique Conditions :\", data['condition'].nunique())\n",
    "data['condition'].value_counts().head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets check Drugs, which were useful to Highest Number of Poeple\n",
    "data[['drugName','usefulCount']][data['usefulCount'] >\n",
    "                    data['usefulCount'].mean()].sort_values(by = 'usefulCount',\n",
    "                                        ascending = False).head(10).reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets remove all the Duplicates from the Dataset\n",
    "data = data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets find the Highest and Lowest Rated Drugs for each Condition\n",
    "\n",
    "@interact\n",
    "def high_low_rate(condition = list(data['condition'].value_counts().index)):\n",
    "    print(\"\\n Top 5 Drugs\")\n",
    "    print(data[data['condition'] == condition][['drugName','usefulness']].sort_values(by = 'usefulness',\n",
    "                                                 ascending = False).head().reset_index(drop = True))\n",
    "    print(\"\\n\\n Bottom 5 Drugs\")\n",
    "    print(data[data['condition'] == condition][['drugName','usefulness']].sort_values(by = 'usefulness',\n",
    "                                                 ascending = True).head().reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
